// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py


// RUN: %clang_cc1 -triple arm64-none-linux-gnu -target-feature +neon -flax-vector-conversions=none \
// RUN: -disable-O0-optnone  -emit-llvm -o - %s | opt -S -passes=instcombine | FileCheck %s

// REQUIRES: aarch64-registered-target

#include <arm_neon.h>

// CHECK-LABEL: @test_vdupb_lane_p8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[VGET_LANE:%.*]] = extractelement <8 x i8> [[A:%.*]], i64 1
// CHECK-NEXT:    ret i8 [[VGET_LANE]]
//
poly8_t test_vdupb_lane_p8(poly8x8_t a){
  return vdupb_lane_p8(a, 1);
}

// CHECK-LABEL: @test_vdupb_laneq_p8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[VGETQ_LANE:%.*]] = extractelement <16 x i8> [[A:%.*]], i64 5
// CHECK-NEXT:    ret i8 [[VGETQ_LANE]]
//
poly8_t test_vdupb_laneq_p8(poly8x16_t a) {
  return vdupb_laneq_p8(a, 5);
}

// CHECK-LABEL: @test_vset_lane_p8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[VSET_LANE:%.*]] = insertelement <8 x i8> [[V:%.*]], i8 [[A:%.*]], i64 3
// CHECK-NEXT:    ret <8 x i8> [[VSET_LANE]]
//
poly8x8_t test_vset_lane_p8(poly8_t a, poly8x8_t v){
  return vset_lane_p8(a, v, 3);
}

// CHECK-LABEL: @test_vset_lane_p16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[VSET_LANE:%.*]] = insertelement <4 x i16> [[V:%.*]], i16 [[A:%.*]], i64 3
// CHECK-NEXT:    ret <4 x i16> [[VSET_LANE]]
//
poly16x4_t test_vset_lane_p16(poly16_t a, poly16x4_t v){
  return vset_lane_p16(a, v, 3);
}

// CHECK-LABEL: @test_vset_lane_p64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[VSET_LANE:%.*]] = insertelement <1 x i64> poison, i64 [[A:%.*]], i64 0
// CHECK-NEXT:    ret <1 x i64> [[VSET_LANE]]
//
poly64x1_t test_vset_lane_p64(poly64_t a, poly64x1_t v){
  return vset_lane_p64(a, v, 0);
}

// CHECK-LABEL: @test_vsetq_lane_p8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[VSET_LANE:%.*]] = insertelement <16 x i8> [[V:%.*]], i8 [[A:%.*]], i64 3
// CHECK-NEXT:    ret <16 x i8> [[VSET_LANE]]
//
poly8x16_t test_vsetq_lane_p8(poly8_t a, poly8x16_t v){
  return vsetq_lane_p8(a, v, 3);
}

// CHECK-LABEL: @test_vsetq_lane_p16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[VSET_LANE:%.*]] = insertelement <8 x i16> [[V:%.*]], i16 [[A:%.*]], i64 3
// CHECK-NEXT:    ret <8 x i16> [[VSET_LANE]]
//
poly16x8_t test_vsetq_lane_p16(poly16_t a, poly16x8_t v){
  return vsetq_lane_p16(a, v, 3);
}

// CHECK-LABEL: @test_vsetq_lane_p64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[VSET_LANE:%.*]] = insertelement <2 x i64> [[V:%.*]], i64 [[A:%.*]], i64 0
// CHECK-NEXT:    ret <2 x i64> [[VSET_LANE]]
//
poly64x2_t test_vsetq_lane_p64(poly64_t a, poly64x2_t v){
  return vsetq_lane_p64(a, v, 0);
}

// CHECK-LABEL: @test_vget_lane_p8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[VGET_LANE:%.*]] = extractelement <8 x i8> [[V:%.*]], i64 2
// CHECK-NEXT:    ret i8 [[VGET_LANE]]
//
poly8_t test_vget_lane_p8(poly8x8_t v){
  return vget_lane_p8(v, 2);
}

// CHECK-LABEL: @test_vget_lane_p16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[VGET_LANE:%.*]] = extractelement <4 x i16> [[V:%.*]], i64 2
// CHECK-NEXT:    ret i16 [[VGET_LANE]]
//
poly16_t test_vget_lane_p16(poly16x4_t v){
  return vget_lane_p16(v, 2);
}

// CHECK-LABEL: @test_vget_lane_p64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[VGET_LANE:%.*]] = extractelement <1 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    ret i64 [[VGET_LANE]]
//
poly64_t test_vget_lane_p64(poly64x1_t v){
  return vget_lane_p64(v, 0);
}

// CHECK-LABEL: @test_vgetq_lane_p8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[VGETQ_LANE:%.*]] = extractelement <16 x i8> [[V:%.*]], i64 2
// CHECK-NEXT:    ret i8 [[VGETQ_LANE]]
//
poly8_t test_vgetq_lane_p8(poly8x16_t v){
  return vgetq_lane_p8(v, 2);
}

// CHECK-LABEL: @test_vgetq_lane_p16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[VGETQ_LANE:%.*]] = extractelement <8 x i16> [[V:%.*]], i64 2
// CHECK-NEXT:    ret i16 [[VGETQ_LANE]]
//
poly16_t test_vgetq_lane_p16(poly16x8_t v){
  return vgetq_lane_p16(v, 2);
}

// CHECK-LABEL: @test_vgetq_lane_p64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[VGETQ_LANE:%.*]] = extractelement <2 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    ret i64 [[VGETQ_LANE]]
//
poly64_t test_vgetq_lane_p64(poly64x2_t v){
  return vgetq_lane_p64(v, 0);
}

// CHECK-LABEL: @test_vcopy_lane_p8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[VSET_LANE:%.*]] = shufflevector <8 x i8> [[B:%.*]], <8 x i8> [[A:%.*]], <8 x i32> <i32 0, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    ret <8 x i8> [[VSET_LANE]]
//
poly8x8_t test_vcopy_lane_p8(poly8x8_t a, poly8x8_t b) {
  return vcopy_lane_p8(a, 0, b, 0);
}

// CHECK-LABEL: @test_vcopy_lane_p16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[VSET_LANE:%.*]] = shufflevector <4 x i16> [[B:%.*]], <4 x i16> [[A:%.*]], <4 x i32> <i32 0, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <4 x i16> [[VSET_LANE]]
//
poly16x4_t test_vcopy_lane_p16(poly16x4_t a, poly16x4_t b) {
  return vcopy_lane_p16(a, 0, b, 0);
}

// CHECK-LABEL: @test_vcopy_lane_p64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    ret <1 x i64> [[B:%.*]]
//
poly64x1_t test_vcopy_lane_p64(poly64x1_t a, poly64x1_t b) {
  return vcopy_lane_p64(a, 0, b, 0);
}

// CHECK-LABEL: @test_vcopyq_lane_p8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i8> [[B:%.*]], <8 x i8> poison, <16 x i32> <i32 0, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>
// CHECK-NEXT:    [[VSET_LANE:%.*]] = shufflevector <16 x i8> [[TMP0]], <16 x i8> [[A:%.*]], <16 x i32> <i32 0, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
// CHECK-NEXT:    ret <16 x i8> [[VSET_LANE]]
//
poly8x16_t test_vcopyq_lane_p8(poly8x16_t a, poly8x8_t b){
  return vcopyq_lane_p8(a, 0, b, 0);
}

// CHECK-LABEL: @test_vcopyq_lane_p16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i16> [[B:%.*]], <4 x i16> poison, <8 x i32> <i32 0, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>
// CHECK-NEXT:    [[VSET_LANE:%.*]] = shufflevector <8 x i16> [[TMP0]], <8 x i16> [[A:%.*]], <8 x i32> <i32 0, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    ret <8 x i16> [[VSET_LANE]]
//
poly16x8_t test_vcopyq_lane_p16(poly16x8_t a, poly16x4_t b){
  return vcopyq_lane_p16(a, 0, b, 0);
}

// CHECK-LABEL: @test_vcopyq_lane_p64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <1 x i64> [[B:%.*]], <1 x i64> poison, <2 x i32> <i32 0, i32 poison>
// CHECK-NEXT:    [[VSET_LANE:%.*]] = shufflevector <2 x i64> [[TMP0]], <2 x i64> [[A:%.*]], <2 x i32> <i32 0, i32 3>
// CHECK-NEXT:    ret <2 x i64> [[VSET_LANE]]
//
poly64x2_t test_vcopyq_lane_p64(poly64x2_t a, poly64x1_t b){
  return vcopyq_lane_p64(a, 0, b, 0);
}

// CHECK-LABEL: @test_vcopy_laneq_p8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[VGETQ_LANE:%.*]] = extractelement <16 x i8> [[B:%.*]], i64 0
// CHECK-NEXT:    [[VSET_LANE:%.*]] = insertelement <8 x i8> [[A:%.*]], i8 [[VGETQ_LANE]], i64 0
// CHECK-NEXT:    ret <8 x i8> [[VSET_LANE]]
//
poly8x8_t test_vcopy_laneq_p8(poly8x8_t a, poly8x16_t b){
  return vcopy_laneq_p8(a, 0, b, 0);
}

// CHECK-LABEL: @test_vcopy_laneq_p16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[VGETQ_LANE:%.*]] = extractelement <8 x i16> [[B:%.*]], i64 0
// CHECK-NEXT:    [[VSET_LANE:%.*]] = insertelement <4 x i16> [[A:%.*]], i16 [[VGETQ_LANE]], i64 0
// CHECK-NEXT:    ret <4 x i16> [[VSET_LANE]]
//
poly16x4_t test_vcopy_laneq_p16(poly16x4_t a, poly16x8_t b){
  return vcopy_laneq_p16(a, 0, b, 0);
}

// CHECK-LABEL: @test_vcopy_laneq_p64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[VSET_LANE:%.*]] = shufflevector <2 x i64> [[B:%.*]], <2 x i64> poison, <1 x i32> zeroinitializer
// CHECK-NEXT:    ret <1 x i64> [[VSET_LANE]]
//
poly64x1_t test_vcopy_laneq_p64(poly64x1_t a, poly64x2_t b){
  return vcopy_laneq_p64(a, 0, b, 0);
}

// CHECK-LABEL: @test_vcopyq_laneq_p8(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[VSET_LANE:%.*]] = shufflevector <16 x i8> [[B:%.*]], <16 x i8> [[A:%.*]], <16 x i32> <i32 0, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
// CHECK-NEXT:    ret <16 x i8> [[VSET_LANE]]
//
poly8x16_t test_vcopyq_laneq_p8(poly8x16_t a, poly8x16_t b){
  return vcopyq_laneq_p8(a, 0, b, 0);
}

// CHECK-LABEL: @test_vcopyq_laneq_p16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[VSET_LANE:%.*]] = shufflevector <8 x i16> [[B:%.*]], <8 x i16> [[A:%.*]], <8 x i32> <i32 0, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    ret <8 x i16> [[VSET_LANE]]
//
poly16x8_t test_vcopyq_laneq_p16(poly16x8_t a, poly16x8_t b){
  return vcopyq_laneq_p16(a, 0, b, 0);
}

// CHECK-LABEL: @test_vcopyq_laneq_p64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[VSET_LANE:%.*]] = shufflevector <2 x i64> [[B:%.*]], <2 x i64> [[A:%.*]], <2 x i32> <i32 0, i32 3>
// CHECK-NEXT:    ret <2 x i64> [[VSET_LANE]]
//
poly64x2_t test_vcopyq_laneq_p64(poly64x2_t a, poly64x2_t b){
  return vcopyq_laneq_p64(a, 0, b, 0);
}
